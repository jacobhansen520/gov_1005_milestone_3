---
title: "Milestone 3"
author: "Jacob Hansen"
date: "2/28/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Reading in relevant libraries.

library(readxl)
library(readr)
library(janitor)
library(tidyverse)
library(tidycensus)
```

**About**

How can a political party maximize the utility of voter registration? I examine recent voter registration data in Arizona, disaggregated by county, to determine the conditions under which more voter registration best translates to more votes. Using census data, this analysis can be further disaggregated to examine the effects that race, income, and geography have on turning registrations into votes.

```{r, echo=FALSE, message=FALSE, warning=FALSE}

# Because of when this project is being done--early in 2020--I want to maximize
# the data available to me. For this reason, I plan on using January data. I
# plan on using the last few years worth of data, but may decide to reach
# further back if time allows and it seems relevant.

# I'm also setting "message" and "warning" to FALSE throughout, because warnings
# are arising from R not knowing what to do with unnecessary empty columns in
# the uncleaned data sets. In the future I may want to edit how I'm cleaning the
# data, but for now the messages and warnings do not seem particularly relevant.

jan_2017 <- read.csv("2017-01-01.csv", skip = 4) %>% 
  clean_names() %>% 
  head(45) %>% 
  select(- x, - x_1, - x_2, - precincts, - total) %>% 
  select(county, date_period, republican, democratic, libertarian, green, other) %>% 
  filter(date_period == "17-Jan") %>% 
  pivot_longer(names_to = "party",
               values_to = "registration_2017",
               cols = c(republican:other))
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}

# I'm going through basically the same process for each of the data sets I'm
# cleaning. Originally I simply cut them down and tried to join and tidy the
# data later, but eventually realized that it was much easier to tidy each data
# set before joining them. After the tidying and joining was done, I was left
# with a data set that had the voter registration numbers for each party in each
# county for every January between 2017 and 2020.

jan_2018 <- read.csv("2018-01-01.csv", skip = 4) %>% 
  clean_names() %>% 
  head(45) %>% 
  select(- x, - x_1, - x_2) %>% 
  select(county, date_period, republican, democratic, libertarian, green, other) %>% 
  filter(date_period == "Jan-18") %>% 
  pivot_longer(names_to = "party",
               values_to = "registration_2018",
               cols = c(republican:other))
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
jan_2019 <- read_csv("2019-01-01.csv", skip = 5) %>% 
  clean_names() %>% 
  head(60) %>% 
  select(- x3, - x5, - x6, - x8, - x9, - x13, - x15, - x17) %>% 
  na.omit() %>% 
  select(county, date_period, republican, democratic, libertarian, green, other) %>% 
  filter(date_period == "Jan-19") %>% 
  pivot_longer(names_to = "party",
               values_to = "registration_2019",
               cols = c(republican:other))
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
jan_2020 <- read_csv("2020-01-21.csv", skip = 5) %>% 
  clean_names() %>% 
  head(60) %>% 
  select(- x3, - x5, - x6, - x8, - x9, - x13, - x15, - x17, - x18, - x19) %>% 
  na.omit() %>% 
  select(county, date_period, republican, democratic, libertarian, green, other) %>% 
  filter(date_period == "Jan-20") %>% 
  pivot_longer(names_to = "party",
               values_to = "registration_2020",
               cols = c(republican:other))
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
jan_2017_to_2018 <- jan_2017 %>% 
  full_join(jan_2018, by = c("county", "party"), suffix = c("_2017", "_2018")) %>% 
  select(- date_period_2017, - date_period_2018)

jan_2017_to_2019 <- jan_2017_to_2018 %>% 
  full_join(jan_2019, by = c("county", "party")) %>% 
  select(- date_period)

jan_2017_to_2020 <- jan_2017_to_2019 %>% 
  full_join(jan_2020, by = c("county", "party")) %>% 
  select(- date_period)
```

Using data from the Arizona Secretary of State, I joined several years' worth of voter registration data for every Arizona county to see how the registration numbers have changed over the last four years.

Because Arizona has a large Native American population, I had to find the appropriate race variable and include it in my census analysis. Below is an example from Pima County, which featured a large percentage of the Tohono O'odham Nation.

Next steps for me will be to figure out the best way to visualize changes in voter registration data, and to determine whether or not I want to add earlier data to my analysis.

```{r, include=FALSE}
# Here, I simply copied the county analysis code we found in class, but I had to
# add a new "racevars" for Native Americans. This was relatively easy to find.

racevars <- c(White = "B02001_002", 
              Black = "B02001_003", 
              Asian = "B02001_005",
              Hispanic = "B03003_003",
              Native_American = "B02001_004")
pima <- get_acs(geography = "tract",
                  variables = racevars, 
                  year = 2018,
                  state = "AZ",
                  county = "Pima County",
                  geometry = TRUE,
                  summary_var = "B02001_001")
```


```{r, echo=FALSE}
pima %>%
  mutate(Percent = 100 * (estimate / summary_est)) %>%
  ggplot(aes(fill = Percent, color = Percent)) +
  facet_wrap(~ variable) +
  geom_sf() +
  scale_fill_viridis_c(direction = -1) +
  scale_color_viridis_c(direction = -1) +
  labs(title = "Racial geography of Pima County, Arizona",
       caption = "Source: American Community Survey 2014-2018") +
  theme_void()
```



